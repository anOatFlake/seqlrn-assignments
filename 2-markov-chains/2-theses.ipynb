{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1ca5525-621f-4874-b22d-871b986abcb3",
   "metadata": {},
   "source": [
    "# Assignment 2: Theses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3049213-915e-4a0e-9745-27d90524de81",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 2) Theses Inspiration\n",
    "\n",
    "Imagine you'd have to write another thesis, and you just can't find a good topic to work on.\n",
    "Well, n-grams to the rescue!\n",
    "Download the `theses.txt` data set from the `Supplemental Materials` in the `Files` section of our Microsoft Teams group.\n",
    "This dataset consists of approx. 1,000 theses topics chosen by students in the past.\n",
    "\n",
    "In this assignment, you will be sampling from n-grams to generate new potential thesis topics.\n",
    "Pay extra attention to preprocessing: How would you handle hyphenated words and acronyms/abbreviations?\n",
    "\n",
    "*In this Jupyter Notebook, we will provide the steps to solve this task and give hints via functions & comments. However, code modifications (e.g., function naming, arguments) and implementation of additional helper functions & classes are allowed. The code aims to help you get started.*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d72777fd-95a9-43c4-94a1-6212835f4ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\flockan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dependencies\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb92ea7f-7008-4345-9f71-6a452a411322",
   "metadata": {},
   "source": [
    "### Prepare the Data\n",
    "\n",
    "1.1 Spend some time on pre-processing. How would you handle hyphenated words and abbreviations/acronyms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91b2bc86-c193-4aa0-99b6-dd5615451fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_theses_titles(filepath):\n",
    "    \"\"\"Loads all theses titles and returns them as a list.\"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    f = open(filepath, mode=\"r\", encoding=\"utf-8\")\n",
    "    lines = f.readlines()\n",
    "    \n",
    "    return lines\n",
    "    \n",
    "    ### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28048a13-313e-4d54-a34a-13fbb70a4a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    \"\"\"Preprocesses and tokenizes the given theses titles for further use.\"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "    result = []\n",
    "    for line in data: \n",
    "        line = line.replace(\"-\", \" \").replace(\"\\\"\", \"\").replace(\"(\", \"\").replace(\")\", \"\") #TODO: Refactor into regex\n",
    "        tokenized = nltk.tokenize.word_tokenize(line, language=\"german\")\n",
    "        result.append(['<s>'] + tokenized + ['</s>'])\n",
    "\n",
    "    return result \n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    ### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd461e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'Johan', 'Gotliebs', 'Einführung', 'in', 'die', 'Buchhaltung', 'Edition', 'und', 'Kommentar', 'zu', 'den', 'Geschäftsvorfällen', 'Faktorbuchhaltung', '</s>']\n"
     ]
    }
   ],
   "source": [
    "basepath = \"C:\\\\Dev\\\\uni\\\\seqlrn-assignments\\\\2-markov-chains\\\\data\\\\\"\n",
    "theses_data = preprocess(load_theses_titles(basepath + \"theses.txt\"))\n",
    "print(theses_data[422])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf63d00c-717f-4db4-8d6b-71d4d2e42041",
   "metadata": {},
   "source": [
    "### Train N-gram Models\n",
    "\n",
    "2.1 Train n-gram models with n = [1, ..., 5]. What about \\<s> and \\</s>?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd849acd-5a69-4ca3-9511-bd6fa56b8e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_n_gram_models(n, data):\n",
    "    \"\"\"This method does calculate all n-grams up to the given n.\"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    ngrams = []\n",
    "    for i in range(1, n+1):\n",
    "        freq = nltk.FreqDist()\n",
    "        for tweet in data: \n",
    "            ngram = list(nltk.ngrams(tweet, i))\n",
    "            freq.update(ngram)\n",
    "             \n",
    "        ngrams.append(freq)\n",
    "    return ngrams\n",
    "\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    ### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5dbbcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gram_models = build_n_gram_models(5, theses_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271b7344-cce3-4003-a404-6bb84fac037d",
   "metadata": {},
   "source": [
    "### Generate the Titles\n",
    "\n",
    "3.1 Write a generator that provides thesis titles of desired length. Please do not use the available `lm.generate` method but write your own.\n",
    "\n",
    "3.2 How can you incorporate seed words?\n",
    "\n",
    "3.3 How do you handle </s> tokens (w.r.t. the desired length?)\n",
    "\n",
    "3.4 If you didn't just copy what nltk's lm.generate does: compare the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6d8644a-4d85-4bdd-aac2-c1607f7b6533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice: If you fix the seed in numpy.random.choice, you get reproducible results.\n",
    "\n",
    "def sample_next_token(prev, n_gram_model):\n",
    "    \"\"\"Samples the next word for the given n_grams.\"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    count = 1\n",
    "    possible_words = []\n",
    "    for ngram in n_gram_model.keys():\n",
    "        if list(ngram[:len(prev)]) == prev:\n",
    "            possible_words.append(ngram) \n",
    "            count += n_gram_model.get(ngram)\n",
    "\n",
    "    suggestions = []\n",
    "    for word in possible_words:\n",
    "        x = n_gram_model.get(word) / count  \n",
    "        suggestions.append((word[-1], x))  \n",
    "        \n",
    "    suggestions.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    selected = np.random.choice(len(suggestions))\n",
    "    \n",
    "    return suggestions[selected][0]\n",
    "\n",
    "    \n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    ### END YOUR CODE\n",
    "\n",
    "\n",
    "def generate(n, n_gram_models, seed, title_length):\n",
    "    \"\"\"Generates a thesis title using the n_grams, seed word and title length.\"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "        \n",
    "    text = ['<s>', seed]\n",
    "    while text[-1] != '</s>' and len(text) < title_length + 1:\n",
    "        # use smaller ngram for start\n",
    "        if len(text) < n:\n",
    "            text.append(sample_next_token(text, n_gram_models[len(text)]))\n",
    "\n",
    "        # biggest ngram model for rest  \n",
    "        else:\n",
    "            text.append(sample_next_token(text[-n+1:], n_gram_models[n-1]))\n",
    "\n",
    "    if text[-1] != '</s>': text.append('</s>')\n",
    "    \n",
    "    return text\n",
    "    \n",
    "    ### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6514c19e-0f09-4453-9d56-ea6f7ae6dddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'Entwicklung', 'intuitiver', 'Interaktionsmöglichkeiten', 'für', 'die', 'graphischen', 'Auswertungen', 'in', 'der', 'Software', 'IngSoft', 'InterWatt', '</s>']\n",
      "['<s>', 'Cloud', 'basierte', 'Kurwenwarnung', '</s>']\n"
     ]
    }
   ],
   "source": [
    "title_length = 20\n",
    "seed_word =  \"Entwicklung\"\n",
    "thesis_title = generate(5, n_gram_models, seed_word, title_length)\n",
    "print(thesis_title)\n",
    "\n",
    "seed_word =  \"Cloud\"\n",
    "thesis_title = generate(5, n_gram_models, seed_word, title_length)\n",
    "print(thesis_title)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
